#!/usr/bin/python
"""
    Joins a parsed file generated by the Stanford parser with a lemma txt file,
    generating XML in the mwetoolkit format. Only dependency annotation and POS
    are considered.
"""

import sys
import pdb
import re

def clean( w ) :
    return w.replace( "\"", "&quot;" )

################################################################################       

def to_xml( s_id, list_of_w ) :
    output = "<s s_id=\"" + str( s_id ) + "\">"
    for w in list_of_w[ : len(list_of_w) - 1 ] :
        (l, t, s, d) = w
        (su,p) = t.rsplit( "/", 1 )

        syndep = ';'.join([syn+":"+dep for (syn,dep) in zip(s,d)])

        output = output + "<w surface=\"" + clean( su ) + \
                          "\" lemma=\"" + clean( l ) + \
                          "\" pos=\"" + clean( p ) + \
                          "\" syn=\"" + clean(syndep) + "\"/>"
                         #"\" syn=\"" + clean( ";".join( s ) ) + \
                         #"\" dep=\"" + clean( ";".join( d ) ) + "\"/>"
    output = output + "</s>"
    return output
       
################################################################################       
        
if len( sys.argv ) < 3 :
    print "Usage : python " + sys.argv[ 0 ] + " <parsed_file> <lemmas_file>"
    sys.exit( -1 )
print "<?xml version=\"1.0\" encoding=\"UTF-8\"?>"
print "<!DOCTYPE corpus SYSTEM \"dtd/mwetoolkit-corpus.dtd\">"
print "<corpus>"
p_file = open( sys.argv[ 1 ] )
l_file = open( sys.argv[ 2 ] )
s_id = 0
try :
    for l_sent in l_file.readlines() :
        l_list = l_sent.strip().split( " " )
        t_sent = p_file.readline()
        if t_sent.strip() == "Sentence skipped: no PCFG fallback." :
            p_file.readline() # Ignore second line of error message
        elif t_sent == "" :
            pass # nothing to do, the parsed file ended prematurely
        else :
            ignore_me = False
            t_list = t_sent.strip().split( " " )
            p_file.readline() # Ignore white line after POS sentence
            p_sent = p_sent = p_file.readline().strip()
            while p_sent != "" :
                p_sent = p_file.readline().strip() # ignore the tree
            p_file.readline() # Ignore white line after tree sentence  
            p_sent = p_file.readline().strip()  
            d_list = [ [] for i in range( len( t_list ) )  ]
            s_list = [ [] for i in range( len( t_list ) )  ]
            while p_sent != "" :
                (syn,w1,w2,ignore) = re.split( "[() ]*", p_sent )
                (ignore,w1pos) = w1.rstrip( "'," ).rsplit( "-", 1 )
                (ignore,w2pos) = w2.rstrip( "'," ).rsplit( "-", 1 )
                try :
                    s_list[ int( w2pos ) - 1 ].append( syn )
                    d_list[ int( w2pos ) - 1 ].append( w1pos )
                    p_sent = p_file.readline().strip()                               
                except IndexError :
                    # discard this sentence
                    p_sent = ""
                    ignore_me = True
            if not ignore_me :
                j_list = map( lambda x, y, w, z: (x, y, w, z), l_list, t_list, s_list, d_list )
                print to_xml( s_id, j_list )
                s_id = s_id + 1
    print "</corpus>"
except Exception :
    pdb.set_trace()
